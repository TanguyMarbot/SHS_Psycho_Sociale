---
title: "tuto_R"
date: "`r Sys.Date()`"
author: "Robert A. T. Avery"
output:
  rmdformats::readthedown:
    highlight: kate
    toc_depth: 4
---

# Tutoriaux R
**SHS - Psychologie sociale**

## 1. Setting up markdown file

### Markdown options und chunks

> Ce premier chunk s'ins√®re avec la commande : alt + cmd + i. A l'int√©rieur, nous pouvons y mette du code qui sera compil√© lorsque nous 'tricoterons' ou 'knit' notre markdown.
  Pour le compiler avant : soit on appuie sur la fl√®che ferte, soit on selectionne le code voulu et on appuie sur cmd et enter.

```{r setup, include=FALSE}
# appel les packages necessaire pour ce format (template) de markdown
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
               warning=FALSE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE)
opts_knit$set(width=75)
```


### Ecrire dans Markdown 

On peut soit √©crire dans le markdown directement. Comme √† l'instant. 

> Ou alors ins√©rer une bo√Æte de texte √† l'aide du symbole >

La mise en page des markdown suit le langage LateX la plupart du temps. Si vous avez des questions de mise en page veuillez vous r√©f√©rez au cheat sheet suivant <https://rstudio.com/resources/cheatsheets/> (aussi sur moodle sous la s√©ance pl√©ni√®re du 17.03.21)

Les outils de mise en page les plus souvent utilis√©s sont :
  * *italic* pour de l'italic
  * **bold** pour bold
  * $$E = MC{2}$$ pour une equation en bloc ou 
  * $\alpha = \beta$ pour equation en ligne
  * Les hashtag signifie les niveau de titre # = titre de niveau 1, ## pour niveau 2, etc.
  * pour ajouter une image $![l√©gende]("../dossier/lien vers l'image en question")$ 
    - sous rubrique
  * les note en bas de page[^1] 
  - [^1]: Sont fait comme ceci

### les packages le plus souvent utilis√©s
```{r packages load, include=TRUE}
#Markdown packages
library(tidyverse)
library(tinytex)
library(rticles)
library(xaringan)
library(sjPlot)
library(lattice)
library(latticeExtra)
library(rmdformats)
library(see)
library(plm)

#Visualisation
library(ggplot2)
library(ggthemes)
library(gmodels)
library(kableExtra)
library(rockchalk)

#Base stats packages
library(plotrix)
library(Rmisc)
library(psych)
library(sjmisc)
library(nortest)
library(pastecs)
library(car)
#library(Rcmdr)
source("../functions/outlierKD.R")
library(effects)
library(lm.beta)

# ez anova tools
library(ez)
library(stats)
library(DescTools)

#MLM packages
library(nlme) # linear models with intra participant correlations (repeated measures)
library(haven)
library(lme4)
library(lmerTest)
```

### Concvention du cours et √©l√©ment de base

  * dans un chunck '<-' permet de cr√©er un objet (avec le nom de gauche) partir de ce qu'il y a √† droite.
  * les objets cr√©√©s sont suivis de .type d'object. Par exemple, pour des donn√©es (.dat)

---------------------------

## 2.Data

### Loading data

Les donn√©es doivent √™tre nettoy√©es avant d'√™tre utilis√©e.
Nous allons voir les commandes pour importer des donn√©es dans votre Markdown

  1. Enregistrer vos fichiers de donn√©es .csv dans le dossier 'data' du projet
  2. Les importer en utilisant le chunk suivant :

```{r import data messy, echo=TRUE, warning=FALSE}
# Data set pas encore nettoy√©
messy.dat <- read_csv("../data/looks_messy.csv")

# pour inspecter les premi√®res lignes
head(messy.dat)
```

 3. Si vos donn√©es sont 'tidy' et wide alors on obtient
 
```{r import data tidy, echo=TRUE, warning=FALSE}
# Data set 'tidy'
tidy.dat <- read_csv("../data/looks_tidy.csv")
head(tidy.dat)
tail(tidy.dat)
```

---

## 3. Describing the data

### Decrire les donn√©es avec des chiffres

#### load the Data 

Pour d√©crire les donn√©es nous allons utiliser la fonction describe du package {psych}
  * Premi√®rement importons les donn√©es de l'exercice.
  
```{r importer data tuto}
tuto.dat <- read_csv("../data/tuto_data.csv")
```

  * Puis on decrit les donn√©es
  
```{r describe tuto_dat}
#Pour le dataset entier
describe(tuto.dat)

#Pour une partie 
describe(tuto.dat$hi_salary)

#En utilisant une formule
test.desc <- aggregate(formula = hi_salary ~ sex, data =tuto.dat, FUN = describe) %>% as.data.frame()
tab_df(test.desc)

# Pour l'erreur standard
std.error(tuto.dat$hi_salary)
```

  * Nous pouvons aussi cr√©er un tableau de descriptives √† partir de certains groupes en combinant certaines fonctions

```{r decrire selon certains facteurs ou modalite}
# Pr√©cision des facteurs : Sous group_by suivi de la base de donn√©es et du ou des facteurs, la pr√©cision des facteurs permet d‚Äôobtenir nos indices statistiques en fonction de leurs modalit√©s :

## Pr√©cision des statistiques et de la variable quantitative : Sous summarise suivi des fonctions d√©sir√©es, en l‚Äôoccurrence le nombre d‚Äôobservations (n), la moyenne (mean) et l‚Äô√©cart-type (sd) de la variable quantitative. Les noms Nombre, Moyenne et EcartType sont les noms que vous souhaitez attribuer aux colonnes pour la fonction d√©sir√©e et peuvent √™tre modifi√©s selon besoins
group_by(tuto.dat, sex, wants_child) %>% 
  dplyr::summarise(
    Nombre = n(), 
    Mediane = median(hi_salary, na.rm = TRUE),
    EcartIQ = IQR(hi_salary, na.rm = TRUE),
    Moyenne = mean(hi_salary, na.rm = TRUE)
  )

```

### D√©crire des donn√©es avec des graphes (plots)

  * Pour d√©crire nos donn√©es de mani√®re visuelles nous avons le choix entre diff√©rents graphiques. Le plus souvent nous utiliseront des
    - histogrammes 
    - boxplots
  * Pour d√©crire des effets (vos r√©sultats), nous utiliseront surtout :
    - des line charts
    - scatterplot avec des lignes de r√©gression.
  * Ne pas oublier de coder en tant que facteur les variables importantes (as.factor(data$la_variable))

 Pour faire les diff√©rents graphiques nous utiliseront les packages "ggplot2" ainsi que "plotrix".
 GGplot2 utilise un language bas√© un 'couche' appel√©s layers dans lesquels ont estime 7 param√®tres importants:

  * the holy 7 parameters
    - *data*
    - *geom_function* (what object is being plotted.. line, bar, etc...)
    - *mapping = aes*(thetics), some *stats* and *positions*
    - what *coordinate system* (often cartesian system x,y)
    -  *facet_function*
  * on peut toujours trouver les arguments en tapant ?geom_votregeomenquestion
  
####  Voici un example d'histogramme
  
```{r histogramme exemple}
hi_salary.histo <- ggplot(tuto.dat, aes(hi_salary)) # cr√©er l'objet ainsi que ins√©rer les data
hi_salary.histo + # + ajoute les layers
  geom_histogram(
    aes(y = stat(density)), size = 0.7,  # quel forme de graph (= geom_) et quel aesthetics va-t-on mapper ?
    alpha = 1, colour = "black", fill ="orange") + # quelques options du geom
  geom_density(size = 0.5) + # un autre pour la densit√©
  labs(x = "axe des x", y = "axe des y", title = "titre", subtitle = "sous-titre", caption = "l√©gende")+ # les l√©gendes 
  theme_bw() # un theme pour faire joli
```

####  Un exemple de boxplot
  
```{r boxplot exemple}
hi_salary.boxplot <- ggplot(tuto.dat, aes(sex, hi_salary)) # cr√©er l'objet ainsi que ins√©rer les data
hi_salary.boxplot + # + ajoute les layers
  geom_boxplot(size = 0.7,  alpha = 1, colour = "black", fill ="orange") + # quelques options du geom
  labs(x = "axe des x", y = "axe des y", title = "titre", subtitle = "sous-titre", caption = "l√©gende")+ # les l√©gendes 
  theme_bw() # un theme pour faire joli
```

####¬†Stats graphs 

  Parfois nous voulons faire un graph d'une interaction pour nos effets. Pour ce faire il faut cr√©er un objet contenant les infos √† ensuite donner au graphique.
  
  S'il y a des NA on peut les enlever en les rep√©rants avec la commande : object <- object[-c(ligneA, ligneB),]
  
  
  * D'abord pour deux variables sans interactions
  
```{r}
# cr√©er l'objet
df <- ddply(tuto.dat, c("condition_exp", "sex"), dplyr::summarize,
            Mean = mean(attractive, na.rm=T),
            SE   = std.error(attractive, na.rm=T))
df
```

```{r bar charts}
attractive.bar <- ggplot(df, aes(x = condition_exp, y = Mean, fill = sex)) 
attractive.bar +
  geom_bar(stat = "identity", position = "dodge") + 
  ggtitle("XXX") + 
  ylab("Score") +
  geom_errorbar(aes(ymin = Mean-SE, ymax = Mean+SE), width = 0.2, position = position_dodge(0.9)) +
  theme_bw()
```

  
  * Pour une interaction
  
```{r}
cond.sex.attractive <- ddply(tuto.dat, .(condition_exp, sex),  # cr√©er l'objet
                     dplyr::summarise, val=mean(attractive, na.rm=T))
cond.sex.attractive # controler l'objet
```

```{r plot le tout}
interaction.plot <- ggplot(tuto.dat, aes(x=condition_exp, y=attractive, colour=sex)) 
interaction.plot + 
  geom_boxplot() + 
  geom_point(data = cond.sex.attractive, aes(y = val)) +
  geom_line(data = cond.sex.attractive, aes(y = val, group = sex)) + 
  ggtitle("Score en fonction de...") + ylab("Score de ...") +
  theme_bw()
```

  * exemple en scatterplot
  
```{r scatterplot example}
example.plot <- ggplot(tuto.dat, aes(condition_exp, attractive, colour = sex)) +
  geom_point(position = position_jitter(width = 0.3, height = 0.1)) + 
  geom_smooth(aes(group = sex),method = lm) +
  labs(
    title = "Scatterplots for test scores",
    subtitle = "s",
    caption = "c",
    x = "x",
    y = "y") +
  theme_bw()

example.plot
```

---

## 4. Assomptions 

  Il convient de contr√¥ler un certain nombres d'assomptions avant de proc√©der aux analyses inf√©rentielles. Celles-ci sont :
  - la normalit√©
  - les outliers
  - heteroscedasticit√©
  - sph√©ricit√©
  - lin√©arit√©

### Normalit√©

  * La normalit√© peut-√™tre control√©e de mani√®re visuelle
    - histogramme (devraient suivre une courbe normale)
    - boxplots (moyenne au milieu de la boite, moustache √©gales, pas d'outliers)
    - qqplot (devraient suivre la diagonale)
    
```{r norm histogramme}
norm.attractive <- ggplot(tuto.dat, aes(attractive))  + 
  geom_histogram(aes(y = ..density..), fill = "white", colour = "black", binwidth = 1) + 
  labs(
    x= "X",
    y = "Y") + 
  stat_function(fun=dnorm, args=list(mean = mean(tuto.dat$attractive, na.rm = TRUE), sd = sd(tuto.dat$attractive, na.rm = TRUE)), colour = "blue", size=1) +
  theme_bw()

norm.attractive 
```

```{r norm boxplot}
# voir section graphique
```
  
  * Avec des chiffres
    - test de Liliefors
      - si significatif alors donn√©e non normales
      - si grand nombre de participant.e.s (N > 50) alors test trop puissant et sera trop souvent sign. -> observation
    - Skew
      - If the skewness is between -0.5 and 0.5, the data are fairly symmetrical
      - If the skewness is between -1 and ‚Äì 0.5 or between 0.5 and 1, the data are moderately skewed
      - If the skewness is less than -1 or greater than 1, the data are highly skewed
    - Kurtosis
      - Should be between -1 and +1 (see excess kurtosis for an application to different sample sizes)

    
```{r example Liliefors}

# test normalit√© en fonction d'un groupe ici feminin
lillie.test(tuto.dat$attractive[tuto.dat$sex=="Female"])
# nombre de cas 
length(tuto.dat$attractive[tuto.dat$sex=="Female"])


lillie.test(tuto.dat$attractive[tuto.dat$sex=="Male"])
length(tuto.dat$attractive[tuto.dat$sex=="Male"])

# on en concluerait que notre distribution n'est pas normale
```

```{r example skew kurtosis}
# pour avoir plusieurs variables
round(stat.desc(tuto.dat[, c("attractive", "hi_salary")], basic = FALSE, norm = TRUE), digits = 3)

# par groupe
by(tuto.dat[, c("attractive", "hi_salary")], tuto.dat$sex, describe) %>% tab_dfs(titles = c("female", "male"))
```

### Outliers

  * On peut contr√¥ler les outliers de mani√®res visuelles avec les boxplots 
  * Pour obtenir des infos plus sp√©cifiques on peut utiliser :
  
```{r detecting outliers}
boxplot(tuto.dat$hi_salary)$out #Valeurs des VE
length(boxplot(tuto.dat$hi_salary)$out) # nombre de VE
```

  * Il convient aussi d'utiliser la fonction (qui n'est malheureusement pas dans un package) outliersKD que l'on peut *source* (comme un library pour un script qui r√©sume une fonction √©crite). Celle ci se trouve dans le dossier 'functions' et il est sourcer au d√©but avec les autres package.
  * Cette fonction permet
    - de voir la valeur de notre moyenne avec et sans
    - ainsi que les boxplots avec et sans
    - l'histogramme de la variable avec et sans
    
  
```{r outlierKD}
#taper dans la console outlierKD(data, la_variable_d'int√©ret)
# puis √©crire oui ou non pour valider le choix. Attention ! ces cas seront remplac√© par des NA
```

### Homog√©n√©it√© des variance

  * Il faut que la variance de chaque variable soient √©gaux afin de pouvoir √™tre comparable.
    - on utilise soit le test de Lavene (qui doit √™tre non significatif) mais celui ci l'est trop souvent alors on utilise aussi 
    - Hartley's F max = le ratio des variances (la valeur finale doit √™tre en dessous de la valeur critique du tableau)
      - le plus large / le plus petit (et le n-1 est le groupe avec le plus grand N)

![Hartley's Fmax table](../plots/hartley_fmax_table.png)
![Hartley's Fmax plot](../plots/hartley_plot.png)

```{r variance homogeneity Hartleys F}
# Levene test
leveneTest(tuto.dat$attractive, tuto.dat$condition_exp, center = mean)  %>%  
  knitr::kable(., digits = 2, format = "html", align = 'c') %>% 
  kableExtra::kable_styling(., bootstrap_options = "striped")

# Hartley's Fmax
ff <- tuto.dat %>% group_by(condition_exp) %>%
  dplyr::summarise(
    Df = n()-1,
    Variance = var(attractive, na.rm = T))
ff$Variance[1] / ff$Variance[2]
```


### Heteroscedasticit√©

  * Il convient de contr√¥ler que la variance des r√©siduels soient √©gales √† chaque degr√© de nos pr√©dicteurs; qu'ils soient donc homoscedastique. Sans quoi nos conditions/variables pr√©dictrice continues ne serait pas comparables.
    - ceci se teste par inspection visuelle:

```{r heteroscedasticity check}
# pour un model simple qui cherche √† pr√©dire l'importance de l'attractivit√© en fonction de la r√©gion langagi√®re et du genre
attractive.mod <- lm(attractive ~ sex + condition_exp + sex*condition_exp, data = tuto.dat, na.action = na.omit)

#fitted values pour plot et std. and studentised residuals dans nos donn√©es
tuto.dat$fitted <- attractive.mod$fitted.values
tuto.dat$standardized.residuals<- rstandard(attractive.mod)
tuto.dat$studentized.residuals<-rstudent(attractive.mod)

# plot des fitted values against std. residuals
scatter.resid <- ggplot(tuto.dat, aes(fitted, studentized.residuals))
scatter.resid + geom_point() + geom_smooth(method = "lm", colour = "Blue")+ labs(x = "Fitted
Values", y = "Studentized Residual")

# qqplot des residuals
qqplot.resid <- ggplot(tuto.dat, aes(sample=tuto.dat$studentized.residuals)) + stat_qq() + labs(x =
"Theoretical Values", y = "Observed Values")
qqplot.resid
```

### independence (of errors)

  * On peut contr√¥ler ceci avec un test de Durbin-Watson test
    - id√©alement √† 2 (pas <1 et > 3)

```{r error independance}
dwt(attractive.mod) 
```


### mutlicolinearit√©

  * Pr√©dicteurs ne doivent pas √™tre parfaitement corr√©l√©s.

  * To check for multicollinearity, use the VIF values. If these values are *less than 10* then that indicates there probably isn‚Äôt cause for concern. If you take the average of VIF values, and this average is not substantially greater than 1, then that also indicates that there‚Äôs no cause for concern.
  
```{r multicolinearity check}
vif(attractive.mod)
1/vif(attractive.mod)
mean(vif(attractive.mod))
```

### Lin√©arit√©

  * La relation entre les variables doit suivre une relation lin√©aire.
  * inspection visuelle : Ce premier graphique permet de savoir si les valeurs pr√©dites (ou fitted values, en x) et les r√©sidus (ou residuals, en y) suivent une distribution bivari√©e lin√©aire. Pour que la condition de lin√©arit√© du mod√®le soit respect√©e, le segment repr√©sent√© en rouge doit se situer, id√©alement, sur une valeur r√©siduelle (ou y) √©gale √† 0. Nous pouvons consid√©rer cette condition respect√©e.

```{r linearity}
## plot(model.1, which = 1) # residuals vs fitted une fois le mod√®le √©crit (cf. 5 )
```


### Sph√©ricit√©

  * Pour les mesures r√©p√©t√©es √† plus de 3 conditions
  * La variance des diff√©rences entre pair de contidions doit √™tre √©gale.
  * test de Mauchly (si on fait avec )
  
---

## 5. Linear regression

### Writting/running models

```{r prep}
factor(tuto.dat$sex)
```

  Le but de a r√©gression lin√©aire permet de savoir si une variable quantitative (r√©gression simple) ou plusieurs variables quantitatives (r√©gression multiple), appel√©es pr√©dicteurs (ou VI quantitatives), sont passible(s) de pr√©dire les valeurs d‚Äôune autre variable quantitative appel√©e crit√®re (ou VD).

  * General form : newModel<-lm(outcome ~ predictor(s), data = dataFrame, na.action = an action))
  
```{r general form}
model.0 <- lm(n_partners ~ sex, data = tuto.dat, na.action = na.omit)
summary (model.0)
```

  * La partie du tableau ¬´ Coefficients ¬ª traite des diff√©rents pr√©dicteurs, des coefficients de la pente (coefficients B non standardis√©s, sous Estimate) 
  * et de leur significativit√© ou non (t-tests, rejet ou non de H0 selon laquelle les coefficients beta de pente sont √©gal √† 0). Si nous prenons les probl√®mes m√©dicaux, le coefficient beta de la pente est de .32 (et significativement diff√©rent de 0 car p < .05). Cela signifie que, lorsque les probl√®mes m√©dicaux augmentent d‚Äôune unit√©, la consommation de drogue augmente de .32 unit√©s.
  * Les statistiques g√©n√©rales de notre mod√®le (pourcentages de variance expliqu√©e et significativit√©).       - Pour rappel, ce mod√®le consid√®re pr√©cis√©ment le genre du‚Ä¢de la participant‚Ä¢e comme pr√©dicteur et le nombre de partenaire comme VD.
    - Le multiple R2 est la variance du crit√®re expliqu√©e par le pr√©dicteur dans l‚Äô√©chantillon, et le R2 ajust√© ce m√™me pourcentage de variance estim√© pour la population.
    
    
 Pour des coefficients de r√©gression standardis√©s on emploie la m√™me formule mais avec lm.beta
 
```{r formule de base avec coefficient std}
lm.beta(model.0)
```
  
  Pour visualiser rapidement les effets on peut employer plot(allEffects(mon_modele.version))
```{r all effects}
plot(allEffects(model.0))
# ici il n'y en a qu'un
```

  Pour n'avoir que les coefficients (√† noter dans notre rapport) :
  
```{r getting coefficients}
coef(model.0)
```

  
### ajouter des pr√©dicteurs

  Souvent nous voulons savoir l'effet d'un pr√©dicteur num√©rique sur notre VD. Il s'agit alors de l'ajouter dans le mod√®le de la m√™me mani√®re.
  
```{r deux predicteurs}
model.1 <- lm(n_partners ~ sex + hi_salary, data = tuto.dat, na.action = na.omit)
summary(model.1)
```
  
  Nous pouvons les visualiser de la mani√®re suivante :

```{r plot deux pred}
# using allEffect
plot(allEffects(model.1))

# the nice way
ggplot(tuto.dat, aes(x=hi_salary, y=n_partners, fill=sex, color=sex)) + 
        geom_point(size = 1.5) + 
        labs(x = "Importance d'avoir haut salaire", y ="Nombre de partenaire", colour = "Genre") +
        scale_color_manual(values=c('#999999','#E69F00')) +
        scale_fill_manual(values =c('#999999','#E69F00')) +
        guides(fill = F) +
        geom_smooth(method=lm) +
        theme_bw()

```

### Ajouter terme d'interaction (moderation)

  Une variable mod√©ratrice (ou mod√©rateur) est une variable qui alt√®re la force, et possiblement la direction, du lien entre un pr√©dicteur et un crit√®re. Ainsi, l‚Äôeffet du pr√©dicteur sur le crit√®re d√©pend √©galement des niveaux de cette variable mod√©ratrice. La mod√©ration est l'√©quivalent de l'effet d'interaction de l'ANOVA pour la r√©gression. 
  
  
  Nous voyons ici sur le plot que nos lignes de r√©gression ne sont pas parrall√®le, il se pourait donc qu'il y ait un effet d'interaction. Il s'agit alors de l'ajouter dans votre mod√®le comme un pr√©dicteur √† part enti√®re.
  
```{r adding interaction term}
model.2 <- lm(n_partners ~ sex + hi_salary + sex*hi_salary, data = tuto.dat, na.action = na.omit)
summary(model.2)
```

```{r plotting interaction term}
plotSlopes(model.2, plotx="hi_salary", modx="sex",
           interval="confidence", main="Graphique de moderation",
           xlab="important haut salaire", ylab="nombre de partenaire")

```
 
  Ici la param√®tre d'interaction n'est pas significatif, nous n'avons donc qu'un seul effet de genre √† reporter.
  
### Comparer des mod√®le

  On peut comparer des mod√®les qui sont nest√© avec la fonction anova()
  
```{r comparing two models}
anova(model.1, model.2)
```
  
  Ici l'output nous montre que notre F score ne s'est pas significativement am√©liorer. En d'autre terme, l'inclusion de cette variable dans notre mod√®le n'a pas su mieux r√©partir la variance de celui-ci.


### Mesure r√©p√©t√©es - quick walkthrough

```{r loading ratio_data}
# nouvelles donn√©es longitudinales
longLoss_ratio <- read_csv("../data/longLoss_ef.csv") 
longLoss_ratio <- longLoss_ratio %>% subset(select = -c(lickert_score))

longLoss_ratio$PE_measure <-factor(longLoss_ratio$PE_measure)
```

```{r anova pour mesures repetees}
model.repeated <- ezANOVA(data = longLoss_ratio,
                         dv = .(ratio_OT),
                         wid = .(participant_ID),
                         within = .(PE_measure),
                         detailed = T, type = 3)
model.repeated
```
  Ceci nous montre que les trois conditions ne sont pas sph√©rique et que nous avons un effet de la mesure r√©p√©t√©e. Pour voir entre quelles conditions de celle-ci elle op√®re nous pouvons faire des tests post-hoc.

```{r test post hoc}
# recreating model sans facteurs intersujets pour voir ou sont les diff√©rences
model.repeated.post <- aov(ratio_OT ~ PE_measure, 
                         data=longLoss_ratio)

# post hoc tests for all variables (other specifiy under 'which' = "")
PostHocTest(model.repeated.post, which=NULL, 
            method="hsd", conf.level=.95)

# summary
summary(lm(model.repeated.post))

```

  et savoir comment les d√©crires en fonctions des variables selectionn√©es
  
```{r repeated descriptives}
# getting descriptives by variable

ezStats(data = longLoss_ratio,
                         dv = .(ratio_OT),
                         wid = .(participant_ID),
                         within = .(PE_measure))
```

```{r repeated plots}
ezPlot(data = longLoss_ratio,
       dv = .(ratio_OT),
       wid = .(participant_ID),
       within = .(PE_measure),
       x = .(PE_measure),
       do_lines = TRUE)
```


---

## 6. Fid√©lit√©

### Choisir ses variables  

  * Lorsque vous aurez diff√©rents items, il conviendra de voir si celles si corr√®lent ensemble afin de savoir s'il est acceptable de toutes les garder dans votre qu√™te de score final.
    - Ceci se fait avec l'alpha de Cronbach
  
  * Tout d'abord, il convient de mesurer les items sur la base des facteurs th√©oriques latent. Par exemple, il se peut que vos items soient une moiti√© en lien avec les √©motions et les autres avec les intentions comportementales. Il faut les s√©parer. On peut faire cela en cr√©ant des subsets. 
  
```{r 6 subsetting}
high_functionning <- tuto.dat[, c("hi_salary",	"fin_ed",	"ambitious", 	"attractive")]
nice <- tuto.dat[, c("kind",	"humour", "wants_child",	"romantic", "creativity",	"honest")]
```
 
  * attention s'il y a des valeurs √† recoder, ceci peut-√™tre fait directement ici (si pas encore fait au moment des nettoyage de donn√©es)
 
```{r 6 reverse coding}
# l'argument keys = c(1, 1, 1, -1) pour un objet √† 4 items ou le dernier est √† inverser
## directement dans la fonction suivante
```

  * la fonction de fiabilit√© et psych::alpha()
  
```{r 6 alpha}
psych::alpha(high_functionning)
psych::alpha(nice)
```

  * Les choses √† garder en t√™te
    - une bonne corr√©lation globale est de .8 (.7 acceptable, attention au dela de .9 les items sont identitiques)
      - ceci correspond aux (raw_apha et leur √©cart type std.alpha)
    - ensuite on a l'alpha global en fonction de si un ou l'autre item est enlev√©
    - Puis on a la colonne r.drop qui nous indique la correlation d'un item avec le reste.
      - attention √† ne pas en avoir en dessous de .3 !
    - le tableau non missing response frequency :
      - nous indique quel pourcentage de personnes ont r√©pondu de la m√™me mani√®re au m√™me item. Utile pour savoir si tout le monde r√©pond identiquement alors probablement que cet item n'est pas tr√®s utile pour diff√©rencier vos participant.e.s.
    - Une fois les items enlev√©es, il s'agit de refaire l'analyse afin de v√©rifier les nouveaux coefficients.

---

## 7. Mediation analysis

### Running Hayes process

```{r calling the process like a package }
source("../extras/process.R")
```

  * Hayes Process utilise le bootstrapping afin de mener √† bien des mod√®les de m√©diation
      - technique √† partir de laquelle la distribution d'√©chantillonnage d'une statistique est estim√©e en prenant des valeurs r√©p√©t√©es (avec remplacement, i.e. que l'on peut reprendre plusieurs fois la m√™me valeurs) de l'ensemble des donn√©es (donc, en traitant les donn√©es comme une population √† partir de laquelle de plus petits √©chantillons sont pr√©lev√©s).
      - La statistique d'int√©r√™t (e.g., la moyenne ou le coefficient b) est calcul√©e pour chaque √©chantillon, √† partir duquel la distribution d'√©chantillonnage de la statistique est estim√©e. 
      - L'erreur type de la statistique est estim√©e comme √©tant l'√©cart type de la distribution d'√©chantillonnage cr√©√©e √† partir des √©chantillons bootstrap. √Ä partir de l√†, des intervalles de confiance et des tests de signification peuvent √™tre calcul√©s.
      
  * Ce programme (~ package) n'accepte que les variables num√©riques
      - attention a recoder ses variables cat√©goriques (genre etc.)
  * Suites d‚Äô√©tapes :
      - $Y_ùëñ=ùëè¬†ÃÇ_ 0+ùëè¬†ÃÇ_1 ùëã_ùëñ+ùúÄ_ùëñ$
      - $M_ùëñ=ùëè¬†ÃÇ_ 0+ùëè¬†ÃÇ_1 ùëã_ùëñ+ùúÄ_ùëñ$
      - $Y_ùëñ=ùëè¬†ÃÇ_ 0+ùëè¬†ÃÇ_1 ùëã_ùëñ+ùëè¬†ÃÇ_2 ùëÄ_ùëñ+ùúÄ_ùëñ$
      - l√† o√π $b_1 ùëã_ùëñ$ est plus petit que dans la premi√®re √©quation
  * pour plus d'info visiter le site 
      - http://www.regorz-statistik.de/en/mediation_process_for_r.html#testing
  
### example de mod√®le 

  * on d√©sire savoir si, dans les donn√©es du cours, la perception du degr√© de la difficult√© , pr√©dite par l'habitude que les √©tudiant.e.s ont de lire ce genre de texte, est expliqu√© par l'appr√©ciation de ce genre d'exercice.
  
```{r model A - replication}
feedback_dat <- read.csv("../data/feedback_data_clean.csv")
process(feedback_dat,
        y = "questions_hard_1",
        x = "usual_1",
        m = "like_it_1",
        effsize =1, # que l'on veut l'output du calcul la taille d'effet
        stand =1, # que l'on d√©sire les coefficient standardis√©s
        modelbt = 1, # all regression coefficient pour toutes les paths (chemins) sont bootstrapped
        boot = 10000, # le nombre de bootstrap que l'on veut faire
        seed = 654321, # set seed permet de repliquer les r√©sultats avec le m√™me point de d√©part
        total = 1, # 1 d√©signe que l'on d√©sire l'output de l'effet total (= c path )
        model = 4) # d√©signe le mod√®le de m√©diation que l'on d√©sire performer 

#  si on veut ajouter des covariates on doit ajouter cov = "age" ou cov = c("age", "gender"), s'il y en a plusieurs

```

  * Pour que l'analyse de m√©diation soit statistiquement significative, il faut 
      - que sous la rubrique : TOTAL, DIRECT, AND INDIRECT EFFECTS OF X ON Y 
      - l'indirect effect's bootstrap confidence intervals ne contiennent pas 0 (si elles contenaient 0, cela representerait un coefficient non significatif)
      - si le direct effect est significatif alors la m√©diation n'est pas totale mais partielle (= le m√©diateur n'explique pas l'enti√©rt√© de la relation entre les deux)
      - pour d√©signer le path a (variable de base X au m√©diateur M) c'est la premi√®re partie de l'output ( ici Outcome Variable: like_it_1)
      - pour d√©signer la path b (du m√©diatieur M √† notre variable d√©pendante Y) c'est la premi√®re partie de l'output (ici Outcome Variable: questions_hard_1)
    * le total effect model c'est l'effet de X sur Y sans prendre en compte M

  * Une fois les analyses faites, reportez vos coefficients (les coefficients de regression standardized) standardis√©s ainsi que leur significativit√© sur une repr√©sentation graphique de votre mod√®le de m√©dation (votre triangle th√©orique).
